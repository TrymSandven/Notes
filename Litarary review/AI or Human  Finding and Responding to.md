AI or Human? Finding and Responding to
Artificial Intelligence in Student Work
========================
Written by Gary d. Fisk

### Introduction: Recent innovations in generative artificial intelligence (AI) technologies have led to an educational environment in which human authorship cannot be assumed, thereby posing a significant challenge to upholding academic integrity.
### Statement of the problem: Both humans and AI detection technologies have difficulty distinguishing between AI-generated vs. human-authored text. This weakness raises a significant possibility of false positive errors: human-authored writing incorrectly judged as AI-generated.
### Literature review: AI detection methodology, whether machine or human-based, is based on writing style characteristics. Empirical evidence demonstrates that AI detection technologies are more sensitive to AI-generated text than human judges, yet a positive finding from these technologies cannot provide absolute certainty of AI plagiarism.
### Teaching implications: Given the uncertainty of detecting AI, a forgiving, pro-growth response to AI academic integrity cases is recommended, such as revise and resubmit decisions.
### Conclusion: Faculty should cautiously embrace the use of AI detection technologies with the understanding that false positive errors will occasionally occur. This use is ethical provided that the responses to problematic cases are approached with the goal of educational growth rather than punishment.

## Detecting AI-Generated Text
AI authorship can sometimes be inferred from subtle leftover traces of AI–human interactions during the generation process. For example, a peer-reviewed paper in Physica Scripta contained the inappropriate phrase “regenerate response” at the end of a mathematical step. This phrase was a fragment from an interactive AI prompt (Conroy, 2023).

The AI style has been variously described as bland, lifeless, or robotic in character (Andrews, 2023; Khanna, 2023). The writing may be overly stylized or formulaic (Andrews, 2023; Gao et al., 2023). A stylized example is listicle formatting: a PowerPoint-like writing style in which short statements are followed by one to three supporting sentences. Another possible AI sign is excessively poetic language—“rich tapestry” and “symphony”—that is unusual for undergraduate student writing (Rivas, 2023; Shrivastava & Levine, 2024).

## Which Detection Method is Best? Human or AI?
The superiority of detection technologies over human judgment is illustrated by Gao et al. (2023), who compared human vs. detection technology performance on the classification of human vs. synthetic writing in scientific abstracts. The human participants were scientists (the study authors) making judgments under blind conditions. The AI detection technology cor- rectly classified most of the synthetic abstracts as being AI-generated (d’ = 2.20) 1 and had a low false positive rate (2%). In contrast, human judges had lower sensitivity (d’ = 1.55) 2 and a much higher false positive rate (14%).

A multitude of commercial AI detection technologies have been offered to educators over the last 2 years. Recommending which of these technologies is the best detector is challenging given the rapid pace of change and variations in the evaluation methodology. The top detection technologies at this time, in no particular order, may be offered by Turnitin, Originality.ai, and CopyLeaks (Walters, 2023; see also Akram, 2023; Elkhatat et al., 2023; Lee, 2023; Weber-Wulff et al., 2023). 

The most critical AI detection issue for educators and students is the false positive rate: Authentic human work that is incorrectly flagged as AI text.  Mistakenly accusing studentsof academic integrity violations may result in student outrage and damaged faculty–student relationships. While detection technologies are recommended, it is impor- tant to understand that the results from these services are no panacea for the challenge raised by AI plagiarism. Detection technology feedback is only a beginning point for educators to use in their grading and judgments (Chechitelli, 2023).